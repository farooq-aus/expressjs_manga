'use strict';

Object.defineProperty(exports, "__esModule", {
  value: true
});

var _cheerio = require('cheerio');

var _cheerio2 = _interopRequireDefault(_cheerio);

var _momentTimezone = require('moment-timezone');

var _momentTimezone2 = _interopRequireDefault(_momentTimezone);

var _pThrottle = require('p-throttle');

var _pThrottle2 = _interopRequireDefault(_pThrottle);

var _errors = require('../errors');

var _errors2 = _interopRequireDefault(_errors);

var _utils = require('../utils');

var _utils2 = _interopRequireDefault(_utils);

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

const TZ = 'UTC';

const throttledGet = (0, _pThrottle2.default)(_utils2.default.getPage, 5, 100);

const getChapterTimestamp = str => {
  let date;

  switch (str.toLowerCase()) {
    case 'today':
      date = _momentTimezone2.default.tz(TZ);
      break;
    case '1 day ago':
    case 'yesterday':
      date = _momentTimezone2.default.tz(TZ).subtract(1, 'day');
      break;
    case '2 days ago':
      date = _momentTimezone2.default.tz(TZ).subtract(2, 'days');
      break;
    default:
      date = _momentTimezone2.default.tz(str, 'MMM Do, YYYY', TZ);
      break;
  }

  return date.startOf('day').unix();
};
const getChapterSlugFromPathname = pathname => fixUrlEncoding(pathname.split('/').filter(Boolean).slice(2, 4).join('/'));
const getPageNumberFromPathname = pathname => parseFloat(pathname.split('/').pop());

const getPageFromHtml = async html => {
  const dom = _cheerio2.default.load(html);
  const src = dom('img#manga-page').attr('src');
  const normalizedSrc = src.startsWith('//') ? `https:${src}` : src;

  return {
    id: normalizedSrc.split('/').pop(),
    url: normalizedSrc
  };
};

const fixUrlEncoding = url => url
// For some reason, utils.normalizeUrl has issues with the '[]' characters
// that sometimes appear in MangaStream URLs, like this one:
// https://readms.net/r/robotxlaserbeam/62%20%5BEND%5D/5180/1
.replace(/\[/g, '%5B').replace(/\]/g, '%5D');

const getPageFromUrl = url => throttledGet(url).then(getPageFromHtml);

const stripLeadingZeroes = str => str.replace(/^0+/, '');
const stripEndMarker = str => str.replace(/ [([]?end[)]]?$/i, '');
const trimChapterNumber = str => {
  return stripEndMarker(stripLeadingZeroes(str));
};

const MangaStreamAdapter = {
  id: 'manga-stream',
  name: 'Manga Stream',

  supportsUrl(url) {
    return _utils2.default.compareDomain(url, 'https://readms.net');
  },

  supportsReading() {
    return true;
  },

  parseUrl(url) {
    // https://readms.net/manga/attack_on_titan
    // https://readms.net/r/attack_on_titan/103/4949/3

    const u = _utils2.default.parseUrl(url);
    const parts = u.pathname.split('/').filter(Boolean);
    const isChapter = u.pathname.startsWith('/r/');

    (0, _utils.invariant)(parts.length > 1, new _errors2.default.InvalidUrlError(url));

    const seriesSlug = parts[1];
    let chapterSlug = null;

    if (isChapter) {
      (0, _utils.invariant)(parts.length > 3, new _errors2.default.InvalidUrlError(url));
      chapterSlug = getChapterSlugFromPathname(u.pathname);
    }

    return { seriesSlug, chapterSlug };
  },

  constructUrl(seriesSlug, chapterSlug) {
    const initial = chapterSlug ? 'r' : 'manga';
    const slug = [initial, seriesSlug, chapterSlug].filter(Boolean).join('/');

    return fixUrlEncoding(_utils2.default.normalizeUrl(`${this._getHost()}/${slug}`));
  },

  _getHost() {
    return `https://readms.net`;
  },

  async getSeries(seriesSlug) {
    const url = this.constructUrl(seriesSlug);

    const html = await throttledGet(url);
    const dom = _cheerio2.default.load(html);

    const title = dom('.main-body h1').text().trim();

    // MangaStream surfaces limited information beyond the series title.
    const coverImageUrl = null;
    const description = null;
    const author = null;
    const status = 'UNKNOWN';

    // MangaStream returns a 200 status for all pages, even when the
    // slug doesn't exist. The "Page Not Found" h1 tag is our clue it's a 404.
    (0, _utils.invariant)(title !== 'Page Not Found', new _errors2.default.NotFoundError(url));

    const chapters = dom('.main-body h1 + table.table tr').slice(1) // Skip the header row
    .get().map(el => {
      const row = dom(el);

      const link = row.find('td > a');
      const right = row.find('td:last-child');

      const titleParts = link.text().split(' - ');
      const chapterNumber = trimChapterNumber(titleParts[0]);
      const title = titleParts[1];

      const slug = getChapterSlugFromPathname(link.attr('href'));
      const url = this.constructUrl(seriesSlug, slug);
      const createdAt = getChapterTimestamp(right.text());

      return { slug, title, url, createdAt, chapterNumber };
    });

    return {
      slug: seriesSlug,
      title,
      description,
      coverImageUrl,
      author,
      status,
      url,
      chapters
    };
  },

  async getChapter(seriesSlug, chapterSlug) {
    const url = this.constructUrl(seriesSlug, chapterSlug);

    const html = await _utils2.default.getPage(url);
    const dom = _cheerio2.default.load(html);

    const pageLinkList = dom('.btn-reader-page ul.dropdown-menu li a');
    const firstPagePathname = pageLinkList.first().attr('href');
    const lastPagePathname = pageLinkList.last().attr('href');

    const firstPageNumber = getPageNumberFromPathname(firstPagePathname);
    const lastPageNumber = getPageNumberFromPathname(lastPagePathname);

    const getPageUrl = pageNumber => `${this.constructUrl(seriesSlug, chapterSlug)}/${pageNumber}`;
    const pageUrls = _utils2.default.range(firstPageNumber, lastPageNumber).map(getPageUrl);

    const pages = await Promise.all(pageUrls.map(url => getPageFromUrl(url)));

    return { slug: chapterSlug, url, pages };
  }
};

exports.default = MangaStreamAdapter;
module.exports = exports['default'];